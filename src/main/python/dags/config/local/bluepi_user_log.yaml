dag_id: bluepi_user_log
default_args:
  owner: "parin.lou"
  start_date: "2020-01-01 00:00:00"
  retries: 1
  retry_delay: "60s"
  timezone: "Asia/Bangkok"
catchup: false
schedule_interval: "*/10 * * * *"
concurrency: 1
description: "extract data from postgres to gcs"
tasks:
  - task_id: start
    operator: airflow.operators.dummy_operator.DummyOperator
  - task_id: load_to_gcs
    operator: airflow.providers.google.cloud.transfers.postgres_to_gcs.PostgresToGCSOperator
    sql: select * from user_log
    bucket: bluepi_exam
    filename: user_log.json
    postgres_conn_id: postgres_bluepi
    google_cloud_storage_conn_id: bluepi_gcs
  - task_id: gcs_to_bq
    operator: operators.custom_gcs_to_bq_operator.CustomGcsToBQOperator
    bucket: bluepi_exam
    source_objects: ['user_log.json']
    destination_project_dataset_table: BLUEPI.user_log
    source_format: NEWLINE_DELIMITED_JSON
    create_disposition: CREATE_IF_NEEDED
    write_disposition: WRITE_TRUNCATE
    bigquery_conn_id: bluepi_bq
    autodetect: False
    schema_file: ./dags/config/schema_data/user_log.schema

flow:
  - start >> load_to_gcs >> gcs_to_bq
